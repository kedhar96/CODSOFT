{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOgvDZpL+whb+ZwuRey8OQu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WPPeHKEycd-v","executionInfo":{"status":"ok","timestamp":1702475950011,"user_tz":-330,"elapsed":8295,"user":{"displayName":"KEDHAR MATTAPALLI","userId":"08843655265356922072"}},"outputId":"b2ff5ca4-d6b9-4d44-b3b0-8b5d2565079e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n"]}],"source":["!pip install transformers\n"]},{"cell_type":"code","source":["from transformers import VisionEncoderDecoderModel, ViTFeatureExtractor, AutoTokenizer\n","import torch\n","from PIL import Image"],"metadata":{"id":"hpVWlXbueamC","executionInfo":{"status":"ok","timestamp":1702476175751,"user_tz":-330,"elapsed":3708,"user":{"displayName":"KEDHAR MATTAPALLI","userId":"08843655265356922072"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["model = VisionEncoderDecoderModel.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n","feature_extractor = ViTFeatureExtractor.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n","tokenizer = AutoTokenizer.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","\n","\n","\n","max_length = 16\n","num_beams = 4\n","gen_kwargs = {\"max_length\": max_length, \"num_beams\": num_beams}\n","def predict_step(image_paths):\n","  images = []\n","  for image_path in image_paths:\n","    i_image = Image.open(image_path)\n","    if i_image.mode != \"RGB\":\n","      i_image = i_image.convert(mode=\"RGB\")\n","\n","    images.append(i_image)\n","\n","  pixel_values = feature_extractor(images=images, return_tensors=\"pt\").pixel_values\n","  pixel_values = pixel_values.to(device)\n","\n","  output_ids = model.generate(pixel_values, **gen_kwargs)\n","\n","  preds = tokenizer.batch_decode(output_ids, skip_special_tokens=True)\n","  preds = [pred.strip() for pred in preds]\n","  return preds\n","\n","predict_step(['sample2.jpg'])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FYttm3d6efk5","executionInfo":{"status":"ok","timestamp":1702476444500,"user_tz":-330,"elapsed":24796,"user":{"displayName":"KEDHAR MATTAPALLI","userId":"08843655265356922072"}},"outputId":"dd61d231-0f24-48e7-8e9e-ab5b5664811b"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['a man riding a horse on top of a beach']"]},"metadata":{},"execution_count":9}]}]}